{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fc63a3a",
   "metadata": {},
   "source": [
    "# Training STS Benchmark\n",
    "This is re-implementation of https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/sts/training_stsbenchmark.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1632254",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a550c27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/farzad/anaconda3/envs/init_sbert/lib/python3.9/site-packages (4.64.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affc94a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 17:26:18.355372: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-29 17:26:18.466415: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-29 17:26:18.488492: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-29 17:26:18.894646: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 17:26:18.894686: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-29 17:26:18.894690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from tqdm.auto import tqdm\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, models, InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3e9332",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5bacd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_dataset_path = \"stsbenchmark.tsv.gz\"\n",
    "\n",
    "# Download the data if not exist\n",
    "if not os.path.exists(sts_dataset_path):\n",
    "    with requests.get(\"https://sbert.net/datasets/stsbenchmark.tsv.gz\", stream=True) as file:\n",
    "        # Get the file size in bytes from the header\n",
    "        total_length = int(file.headers.get(\"Content-Length\"))\n",
    "        \n",
    "        # Implement the ProgressBar\n",
    "        with tqdm.wrapattr(file.raw, \"read\", total=total_length, desc=\"\") as raw:\n",
    "            with open(f\"{os.path.basename(file.url)}\", 'wb') as output:\n",
    "                # Save the output as a file\n",
    "                shutil.copyfileobj(raw, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a9808",
   "metadata": {},
   "source": [
    "### Set Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be58d555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output/training_stsbenchmark_bert-base-uncased-2022-11-29_17-26-35'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = \"output/training_stsbenchmark_\" + model_name.replace('/', '-') + \"-\" + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "model_save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0c634b",
   "metadata": {},
   "source": [
    "### Create Model Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c5db1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "word_embedding_model = models.Transformer(model_name)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                              pooling_mode_mean_tokens=True,\n",
    "                              pooling_mode_cls_token=False,\n",
    "                              pooling_mode_max_tokens=False)\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b4fab3",
   "metadata": {},
   "source": [
    "### Creating the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "910c4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloader\n",
    "train_data = []\n",
    "dev_data = []\n",
    "test_data = []\n",
    "\n",
    "with gzip.open(sts_dataset_path, 'rt', encoding='utf8') as file:\n",
    "    df = pd.read_csv(\"/home/farzad/Downloads/stsbenchmark.tsv\", delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for _, row in df.iterrows():\n",
    "        # We should normalize the scores b/w 0-1 (by default the values are b/w 0-5)\n",
    "        score = row[\"score\"] / 5.0\n",
    "        datapoint = InputExample(texts=[row[\"sentence1\"], row[\"sentence2\"]], label=score)\n",
    "        \n",
    "        if row[\"split\"] == \"train\":\n",
    "            train_data.append(datapoint)\n",
    "        elif row[\"split\"] == \"dev\":\n",
    "            dev_data.append(datapoint)\n",
    "        else:\n",
    "            test_data.append(datapoint)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(dev_data, name=\"sts-dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64449e19",
   "metadata": {},
   "source": [
    "### Configuring the Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6b22f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 10% of the training data as warmup\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1719daa5",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b76e7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291b1e3fcdfd41e5bfa77e8ae37eccde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a7c36ed0ac45e2b0a3f298137f9950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6fcf84d9fe442a89dd66cf9bfdaaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c01b8cf5a540768bbc02ddb2dbeef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4469c2a79d64d6e96a63d75aec567f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "         evaluator=evaluator,\n",
    "         evaluation_steps=1000,\n",
    "         epochs=num_epochs,\n",
    "         warmup_steps=warmup_steps,\n",
    "         output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "458131a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8413889311406069"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = SentenceTransformer(model_save_path)  # Load in case you have a saved model and did not train one.\n",
    "test_evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(test_data, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ef8d9",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/sts/training_stsbenchmark.py\n",
    "\n",
    "[2] [How To: Progress Bars for Python Downloads](https://www.alpharithms.com/progress-bars-for-python-downloads-580122/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:init_sbert]",
   "language": "python",
   "name": "conda-env-init_sbert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
